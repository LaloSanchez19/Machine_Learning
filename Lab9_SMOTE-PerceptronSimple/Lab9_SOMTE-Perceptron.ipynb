{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adfe6cfd-0a45-4381-83ea-ae005824c870",
   "metadata": {},
   "source": [
    "# Lab 9: SMOTE y Perceptrón Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0848fa-51ee-483a-9385-7a5c065ede6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce804284-035d-405b-a1d7-fefe5b99d89a",
   "metadata": {},
   "source": [
    "#### Clasificador Euclidiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637e2fcb-8b59-4637-84f6-293cb33e5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el clasificador de distancia mínima\n",
    "class ClasificadorDistanciaMinima:\n",
    "    def ajustar(self, X_entrenamiento, y_entrenamiento):\n",
    "        # Calcula el centroide para cada clase en el conjunto de entrenamiento\n",
    "        self.centroides = {}\n",
    "        clases = set(y_entrenamiento)\n",
    "        #print(clases)\n",
    "        X_entrenamiento = X_entrenamiento.apply(pd.to_numeric, errors='coerce')\n",
    "        for clase in clases:\n",
    "            muestras_clase = [x for x, y in zip(X_entrenamiento.values, y_entrenamiento) if y == clase]\n",
    "            #print(X_entrenamiento.dtypes)\n",
    "            centroide = [sum(caracteristica) / len(muestras_clase) for caracteristica in zip(*muestras_clase)]\n",
    "            self.centroides[clase] = centroide\n",
    "\n",
    "    def predecir(self, X_prueba):\n",
    "        predicciones = []\n",
    "        X_prueba = X_prueba.apply(pd.to_numeric,errors='coerce')\n",
    "        for x in X_prueba.values:\n",
    "            distancias = {clase: sum((xi - ci) ** 2 for xi, ci in zip(x, centroide)) ** 0.5 \n",
    "                          for clase, centroide in self.centroides.items()}\n",
    "            predicciones.append(min(distancias, key=distancias.get))\n",
    "        return predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cd1b03-0869-4562-ac62-7d87de317e16",
   "metadata": {},
   "source": [
    "#### Clasificador 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab0d232-8469-43a4-8d83-4fc94dc7c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clasificador1NN:\n",
    "    def ajustar(self, X_train, y_train):\n",
    "        X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        y_train = pd.to_numeric(y_train, errors='coerce').fillna(0)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def predecir(self, X_test):\n",
    "        y_pred = []\n",
    "        \n",
    "        X_test = X_test.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        \n",
    "        for _, x in X_test.iterrows():  # Iterar sobre las filas de X_test\n",
    "            distancias = np.sqrt(np.sum((self.X_train - x) ** 2, axis=1))\n",
    "            \n",
    "            idx_vecino = np.argmin(distancias)\n",
    "            \n",
    "            y_pred.append(self.y_train.iloc[idx_vecino])\n",
    "        \n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959936ab",
   "metadata": {},
   "source": [
    "#### Perceptron simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26273ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, Learn_Rate=0.5, Iterations=10):\n",
    "        self.learn_rate = Learn_Rate\n",
    "        self.Iterations = Iterations\n",
    "        self.errors = []\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Inicializar los pesos incluyendo el sesgo (primer peso)\n",
    "        self.weights = np.zeros(1 + x.shape[1])\n",
    "        x = x.select_dtypes(include=[np.number])\n",
    "        x = x.to_numpy()\n",
    "        for i in range(self.Iterations):\n",
    "            error = 0\n",
    "            for xi, target in zip(x, y):\n",
    "                target_adj = -1 if target == 0 else 1\n",
    "                update = self.learn_rate * (target_adj - self.predict(xi, convert_output=False))\n",
    "                self.weights[1:] += update * xi\n",
    "                self.weights[0] += update\n",
    "                error += int(update != 0)\n",
    "            self.errors.append(error)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, x):\n",
    "        return np.dot(x, self.weights[1:]) + self.weights[0]\n",
    "\n",
    "    def predict(self, x, convert_output=True):\n",
    "        pred = np.where(self.net_input(x) >= 0.0, 1, -1)\n",
    "        \n",
    "        if convert_output:\n",
    "            return np.where(pred == 1, 2, 0)\n",
    "        else:\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa710a-8fbf-4b1d-b452-3d5101e2a15a",
   "metadata": {},
   "source": [
    "#### Hold-Out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479b19fc-2566-492c-ab2a-a7fe6dca2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_out_split(data, labels, test_size=0.3):\n",
    "    combined = data.copy()\n",
    "    combined['label'] = labels\n",
    "    \n",
    "    combined = combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    split_index = int(len(combined) * (1 - test_size))\n",
    "    \n",
    "    train_data = combined.iloc[:split_index, :-1]  # Todas las columnas excepto la última (labels)\n",
    "    test_data = combined.iloc[split_index:, :-1]\n",
    "    train_labels = combined.iloc[:split_index, -1]  # Solo la última columna (labels)\n",
    "    test_labels = combined.iloc[split_index:, -1]\n",
    "    \n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f00be-39c6-46cb-b36a-e35eda262920",
   "metadata": {},
   "source": [
    "#### Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4f192c5-904a-4b96-a106-1953fd246a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_split(data, labels, k=5):\n",
    "    if len(data) != len(labels):\n",
    "        raise ValueError(\"El número de muestras en data y labels debe ser el mismo.\")\n",
    "\n",
    "    combined = pd.concat([data, labels], axis=1)\n",
    "\n",
    "    combined = combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    fold_size = len(combined) // k\n",
    "    remainder = len(combined) % k\n",
    "\n",
    "    folds = []\n",
    "    start = 0\n",
    "\n",
    "    for i in range(k):\n",
    "        # Calcular el tamaño del fold actual\n",
    "        current_fold_size = fold_size + (1 if i < remainder else 0)\n",
    "        end = start + current_fold_size\n",
    "\n",
    "        # Datos de prueba para el fold actual\n",
    "        test_data = combined.iloc[start:end, :-1]\n",
    "        test_labels = combined.iloc[start:end, -1]\n",
    "\n",
    "        # Datos de entrenamiento: todo excepto el fold actual\n",
    "        train_data = pd.concat([combined.iloc[:start, :-1], combined.iloc[end:, :-1]], axis=0)\n",
    "        train_labels = pd.concat([combined.iloc[:start, -1], combined.iloc[end:, -1]], axis=0)\n",
    "\n",
    "        folds.append((train_data, test_data, train_labels, test_labels))\n",
    "        start = end\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2d5fe-5ee5-4b99-a5ca-c23f2c6ee903",
   "metadata": {},
   "source": [
    "#### Matriz de confusion y metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7122e15-75f3-43d3-bf1f-5452a3aebc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificationReport(y_true, y_pred):\n",
    "    # Obtener etiquetas únicas en las predicciones y reales\n",
    "    labels = sorted(set(y_true) | set(y_pred))\n",
    "    etiqueta_to_indice = {etiqueta: i for i, etiqueta in enumerate(labels)}\n",
    "    \n",
    "    # Calcular la matriz de confusión\n",
    "    matriz_confusion = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "    for real, pred in zip(y_true, y_pred):\n",
    "        i = etiqueta_to_indice[real]\n",
    "        j = etiqueta_to_indice[pred]\n",
    "        matriz_confusion[i, j] += 1\n",
    "    \n",
    "    # Calcular True Positives, False Positives, y False Negatives globales\n",
    "    TP = np.diag(matriz_confusion).sum()  # Suma de la diagonal\n",
    "    FP = matriz_confusion.sum(axis=0) - np.diag(matriz_confusion)\n",
    "    FN = matriz_confusion.sum(axis=1) - np.diag(matriz_confusion)\n",
    "    \n",
    "    # Precisión, Recall, y F1-score generales\n",
    "    precision_global = TP / (TP + FP.sum()) if (TP + FP.sum()) > 0 else 0\n",
    "    recall_global = TP / (TP + FN.sum()) if (TP + FN.sum()) > 0 else 0\n",
    "    f1_score_global = 2 * (precision_global * recall_global) / (precision_global + recall_global) if (precision_global + recall_global) > 0 else 0\n",
    "    accuracy = TP / matriz_confusion.sum()\n",
    "    \n",
    "    # Convertir matriz de confusión a DataFrame para visualización\n",
    "    matriz_confusion_df = pd.DataFrame(matriz_confusion, index=labels, columns=labels)\n",
    "\n",
    "    return {\n",
    "        'precision_global': precision_global,\n",
    "        'recall_global': recall_global,\n",
    "        'f1_score_global': f1_score_global,\n",
    "        'accuracy': accuracy\n",
    "    }, matriz_confusion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df724fa-03ca-4a21-8cee-27e7a87a5784",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "378e6b8f-5348-4d0f-9656-a4c2fcea2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(X_train,y_train):\n",
    "    counter = Counter(y_train)\n",
    "    print('Before', counter)\n",
    "\n",
    "    # oversampling the train dataset using SMOTE\n",
    "    smt = SMOTE(random_state=42)\n",
    "    X_train_sm, y_train_sm = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "    counter = Counter(y_train_sm)\n",
    "    print('After', counter)\n",
    "    return X_train_sm,y_train_sm   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279368d",
   "metadata": {},
   "source": [
    "## Primera parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b20e5253-c7d7-4781-8f89-86fa0a00a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = pd.read_csv('dataset/glass.csv')\n",
    "Xglass = glass.drop(\"Type\", axis = 1)\n",
    "Yglass = glass[\"Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0754be8c-424f-48e3-ae94-ab1aeb560035",
   "metadata": {},
   "source": [
    "### Antes SMOKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4452d0e7-b02c-4586-b550-3f62e334ff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Holdout de distancia minima**\n",
      "Matriz de Confusión:\n",
      "   1   2  3  5  6   7\n",
      "1  9   2  8  0  0   0\n",
      "2  1  10  5  6  0   0\n",
      "3  1   0  3  0  0   0\n",
      "5  0   0  0  4  0   0\n",
      "6  0   1  0  0  2   0\n",
      "7  0   0  1  2  0  10\n",
      "\n",
      "Reporte de Clasificación General:\n",
      "Precisión: 0.58\n",
      "Recall: 0.58\n",
      "F1-Score: 0.58\n",
      "Exactitud (Accuracy): 0.58\n",
      "\n",
      "**Fold con distancia minima**\n",
      "Matriz de Confusión Total:\n",
      "    1   2   3   5   6   7\n",
      "1  40   5  25   0   0   0\n",
      "2  37  11  17  10   1   0\n",
      "3  11   0   6   0   0   0\n",
      "5   0   0   0  12   2   0\n",
      "6   0   2   1   0  13   1\n",
      "7   0   0   3   1   1  15\n",
      "Resultados Promedio de Validación Cruzada:\n",
      "Precisión Promedio: 0.45\n",
      "Recall Promedio: 0.45\n",
      "F1-Score Promedio: 0.45\n",
      "Exactitud (Accuracy) Promedio: 0.45\n",
      "\n",
      "**Holdout con 1NN**\n",
      "Matriz de Confusión:\n",
      "    1   2  3  5  6  7\n",
      "1  15   3  1  0  0  0\n",
      "2   5  16  0  1  0  0\n",
      "3   3   0  1  0  0  0\n",
      "5   0   0  0  4  0  0\n",
      "6   0   1  0  0  2  0\n",
      "7   1   1  1  0  1  9\n",
      "\n",
      "Reporte de Clasificación General:\n",
      "Precisión: 0.72\n",
      "Recall: 0.72\n",
      "F1-Score: 0.72\n",
      "Exactitud (Accuracy): 0.72\n",
      "\n",
      "**Fold con 1NN**\n",
      "Matriz de Confusión Total:\n",
      "    1   2  3   5   6   7\n",
      "1  54   9  7   0   0   0\n",
      "2  15  52  3   2   4   0\n",
      "3  12   0  7   0   0   0\n",
      "5   0   0  1  13   2   0\n",
      "6   0   2  0   1  17   0\n",
      "7   0   0  1   1   0  11\n",
      "Resultados Promedio de Validación Cruzada:\n",
      "Precisión Promedio: 0.72\n",
      "Recall Promedio: 0.72\n",
      "F1-Score Promedio: 0.72\n",
      "Exactitud (Accuracy) Promedio: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Clasificador con distancia minima\n",
    "clasificador = ClasificadorDistanciaMinima()\n",
    "glassX_train, glassX_test, glassY_train, glassY_test = hold_out_split(Xglass, Yglass)\n",
    "\n",
    "clasificador.ajustar(glassX_train, glassY_train)\n",
    "predicciones_holdout = clasificador.predecir(glassX_test)\n",
    "reporte_general, matriz_confusion = classificationReport(glassY_test, predicciones_holdout)\n",
    "\n",
    "print(\"**Holdout de distancia minima**\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(matriz_confusion)\n",
    "\n",
    "print(\"\\nReporte de Clasificación General:\")\n",
    "print(f\"Precisión: {reporte_general['precision_global']:.2f}\")\n",
    "print(f\"Recall: {reporte_general['recall_global']:.2f}\")\n",
    "print(f\"F1-Score: {reporte_general['f1_score_global']:.2f}\")\n",
    "print(f\"Exactitud (Accuracy): {reporte_general['accuracy']:.2f}\")\n",
    "\n",
    "#print(predicciones_holdout)\n",
    "\n",
    "folds = k_fold_split(Xglass, Yglass, k=10)\n",
    "\n",
    "precision_total = 0\n",
    "recall_total = 0\n",
    "f1_score_total = 0\n",
    "accuracy_total = 0\n",
    "\n",
    "num_clases = len(set(Yglass))  # Número de clases en el conjunto de datos\n",
    "matriz_confusion_total = np.zeros((num_clases, num_clases), dtype=int)\n",
    "\n",
    "for i, (X_train, X_test, y_train, y_test) in enumerate(folds):\n",
    "    clasificador.ajustar(X_train, y_train)\n",
    "    predictions = clasificador.predecir(X_test)\n",
    "\n",
    "    reporte, matriz_confusion = classificationReport(y_test, predictions)\n",
    "    \n",
    "    # Acumular las métricas de este fold\n",
    "    precision_total += reporte['precision_global']\n",
    "    recall_total += reporte['recall_global']\n",
    "    f1_score_total += reporte['f1_score_global']\n",
    "    accuracy_total += reporte['accuracy']\n",
    "    \n",
    "    # Asegurar que la matriz de confusión tenga el tamaño adecuado\n",
    "    if matriz_confusion.shape != matriz_confusion_total.shape:\n",
    "        # Redimensionar matriz de confusión del fold actual\n",
    "        matriz_confusion_expanded = np.zeros_like(matriz_confusion_total)\n",
    "        matriz_confusion_expanded[:matriz_confusion.shape[0], :matriz_confusion.shape[1]] = matriz_confusion\n",
    "        matriz_confusion = matriz_confusion_expanded\n",
    "\n",
    "    # Acumular la matriz de confusión\n",
    "    matriz_confusion_total += matriz_confusion\n",
    "    \n",
    "# Calcular promedios de las métricas\n",
    "num_folds = len(folds)\n",
    "precision_promedio = precision_total / num_folds\n",
    "recall_promedio = recall_total / num_folds\n",
    "f1_score_promedio = f1_score_total / num_folds\n",
    "accuracy_promedio = accuracy_total / num_folds\n",
    "\n",
    "# Imprimir matriz de confusión total\n",
    "print(\"\\n**Fold con distancia minima**\")\n",
    "print(\"Matriz de Confusión Total:\")\n",
    "print(matriz_confusion_total)\n",
    "\n",
    "# Imprimir resultados generales promedio\n",
    "print(\"Resultados Promedio de Validación Cruzada:\")\n",
    "print(f\"Precisión Promedio: {precision_promedio:.2f}\")\n",
    "print(f\"Recall Promedio: {recall_promedio:.2f}\")\n",
    "print(f\"F1-Score Promedio: {f1_score_promedio:.2f}\")\n",
    "print(f\"Exactitud (Accuracy) Promedio: {accuracy_promedio:.2f}\")\n",
    "\n",
    "# Clasificador con 1NN\n",
    "clasificador = clasificador1NN()\n",
    "clasificador.ajustar(glassX_train,glassY_train)\n",
    "predicciones = clasificador.predecir(glassX_test)\n",
    "reporte_general, matriz_confusion = classificationReport(glassY_test, predicciones)\n",
    "print(\"\\n**Holdout con 1NN**\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(matriz_confusion)\n",
    "\n",
    "print(\"\\nReporte de Clasificación General:\")\n",
    "print(f\"Precisión: {reporte_general['precision_global']:.2f}\")\n",
    "print(f\"Recall: {reporte_general['recall_global']:.2f}\")\n",
    "print(f\"F1-Score: {reporte_general['f1_score_global']:.2f}\")\n",
    "print(f\"Exactitud (Accuracy): {reporte_general['accuracy']:.2f}\")\n",
    "\n",
    "\n",
    "precision_total = 0\n",
    "recall_total = 0\n",
    "f1_score_total = 0\n",
    "accuracy_total = 0\n",
    "\n",
    "num_clases = len(set(Yglass))  # Número de clases en el conjunto de datos\n",
    "matriz_confusion_total = np.zeros((num_clases, num_clases), dtype=int)\n",
    "\n",
    "for i, (X_train, X_test, y_train, y_test) in enumerate(folds):\n",
    "    clasificador.ajustar(X_train, y_train)\n",
    "    predictions = clasificador.predecir(X_test)\n",
    "\n",
    "    reporte, matriz_confusion = classificationReport(y_test, predictions)\n",
    "    \n",
    "    # Acumular las métricas de este fold\n",
    "    precision_total += reporte['precision_global']\n",
    "    recall_total += reporte['recall_global']\n",
    "    f1_score_total += reporte['f1_score_global']\n",
    "    accuracy_total += reporte['accuracy']\n",
    "    \n",
    "    # Asegurar que la matriz de confusión tenga el tamaño adecuado\n",
    "    if matriz_confusion.shape != matriz_confusion_total.shape:\n",
    "        # Redimensionar matriz de confusión del fold actual\n",
    "        matriz_confusion_expanded = np.zeros_like(matriz_confusion_total)\n",
    "        matriz_confusion_expanded[:matriz_confusion.shape[0], :matriz_confusion.shape[1]] = matriz_confusion\n",
    "        matriz_confusion = matriz_confusion_expanded\n",
    "\n",
    "    # Acumular la matriz de confusión\n",
    "    matriz_confusion_total += matriz_confusion\n",
    "\n",
    "# Calcular promedios de las métricas\n",
    "num_folds = len(folds)\n",
    "precision_promedio = precision_total / num_folds\n",
    "recall_promedio = recall_total / num_folds\n",
    "f1_score_promedio = f1_score_total / num_folds\n",
    "accuracy_promedio = accuracy_total / num_folds\n",
    "\n",
    "# Imprimir matriz de confusión total\n",
    "print(\"\\n**Fold con 1NN**\")\n",
    "print(\"Matriz de Confusión Total:\")\n",
    "print(matriz_confusion_total)\n",
    "\n",
    "# Imprimir resultados generales promedio\n",
    "print(\"Resultados Promedio de Validación Cruzada:\")\n",
    "print(f\"Precisión Promedio: {precision_promedio:.2f}\")\n",
    "print(f\"Recall Promedio: {recall_promedio:.2f}\")\n",
    "print(f\"F1-Score Promedio: {f1_score_promedio:.2f}\")\n",
    "print(f\"Exactitud (Accuracy) Promedio: {accuracy_promedio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be391805",
   "metadata": {},
   "source": [
    "### Despues de SMOKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74890895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({2: 76, 1: 70, 7: 29, 3: 17, 5: 13, 6: 9})\n",
      "After Counter({1: 76, 2: 76, 3: 76, 5: 76, 6: 76, 7: 76})\n",
      "**Holdout de distancia minima**\n",
      "Matriz de Confusión:\n",
      "    1  2   3   5   6   7\n",
      "1  10  6  11   0   0   0\n",
      "2   6  5   3   3   0   0\n",
      "3   4  0  22   0   0   0\n",
      "5   0  1   1  21   0   0\n",
      "6   0  0   0   0  17   1\n",
      "7   0  0   2   1   3  20\n",
      "\n",
      "Reporte de Clasificación General:\n",
      "Precisión: 0.69\n",
      "Recall: 0.69\n",
      "F1-Score: 0.69\n",
      "Exactitud (Accuracy): 0.69\n",
      "\n",
      "**Fold con distancia minima**\n",
      "Matriz de Confusión Total:\n",
      "    1   2   3   5   6   7\n",
      "1  41   7  28   0   0   0\n",
      "2  27  12  26  10   1   0\n",
      "3  20   0  56   0   0   0\n",
      "5   0   1   3  65   0   7\n",
      "6   0   0   0   3  69   4\n",
      "7   0   0   5   2   8  61\n",
      "Resultados Promedio de Validación Cruzada:\n",
      "Precisión Promedio: 0.67\n",
      "Recall Promedio: 0.67\n",
      "F1-Score Promedio: 0.67\n",
      "Exactitud (Accuracy) Promedio: 0.67\n",
      "\n",
      "**Holdout con 1NN**\n",
      "Matriz de Confusión:\n",
      "    1   2   3   5   6   7\n",
      "1  19   4   4   0   0   0\n",
      "2   4  12   0   1   0   0\n",
      "3   3   0  23   0   0   0\n",
      "5   0   0   0  23   0   0\n",
      "6   0   0   0   0  18   0\n",
      "7   0   1   0   0   1  24\n",
      "\n",
      "Reporte de Clasificación General:\n",
      "Precisión: 0.87\n",
      "Recall: 0.87\n",
      "F1-Score: 0.87\n",
      "Exactitud (Accuracy): 0.87\n",
      "\n",
      "**Fold con 1NN**\n",
      "Matriz de Confusión Total:\n",
      "    1   2   3   5   6   7\n",
      "1  53   7  16   0   0   0\n",
      "2  13  54   5   2   2   0\n",
      "3   8   1  66   0   0   1\n",
      "5   0   0   0  76   0   0\n",
      "6   0   0   0   1  75   0\n",
      "7   0   2   1   0   1  72\n",
      "Resultados Promedio de Validación Cruzada:\n",
      "Precisión Promedio: 0.87\n",
      "Recall Promedio: 0.87\n",
      "F1-Score Promedio: 0.87\n",
      "Exactitud (Accuracy) Promedio: 0.87\n"
     ]
    }
   ],
   "source": [
    "Xglass,Yglass = smote(Xglass,Yglass)\n",
    "\n",
    "# Clasificador con distancia minima\n",
    "clasificador = ClasificadorDistanciaMinima()\n",
    "glassX_train, glassX_test, glassY_train, glassY_test = hold_out_split(Xglass, Yglass)\n",
    "\n",
    "clasificador.ajustar(glassX_train, glassY_train)\n",
    "predicciones_holdout = clasificador.predecir(glassX_test)\n",
    "reporte_general, matriz_confusion = classificationReport(glassY_test, predicciones_holdout)\n",
    "\n",
    "print(\"**Holdout de distancia minima**\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(matriz_confusion)\n",
    "\n",
    "print(\"\\nReporte de Clasificación General:\")\n",
    "print(f\"Precisión: {reporte_general['precision_global']:.2f}\")\n",
    "print(f\"Recall: {reporte_general['recall_global']:.2f}\")\n",
    "print(f\"F1-Score: {reporte_general['f1_score_global']:.2f}\")\n",
    "print(f\"Exactitud (Accuracy): {reporte_general['accuracy']:.2f}\")\n",
    "\n",
    "#print(predicciones_holdout)\n",
    "\n",
    "folds = k_fold_split(Xglass, Yglass, k=10)\n",
    "\n",
    "precision_total = 0\n",
    "recall_total = 0\n",
    "f1_score_total = 0\n",
    "accuracy_total = 0\n",
    "\n",
    "num_clases = len(set(Yglass))  # Número de clases en el conjunto de datos\n",
    "matriz_confusion_total = np.zeros((num_clases, num_clases), dtype=int)\n",
    "\n",
    "for i, (X_train, X_test, y_train, y_test) in enumerate(folds):\n",
    "    clasificador.ajustar(X_train, y_train)\n",
    "    predictions = clasificador.predecir(X_test)\n",
    "\n",
    "    reporte, matriz_confusion = classificationReport(y_test, predictions)\n",
    "    \n",
    "    # Acumular las métricas de este fold\n",
    "    precision_total += reporte['precision_global']\n",
    "    recall_total += reporte['recall_global']\n",
    "    f1_score_total += reporte['f1_score_global']\n",
    "    accuracy_total += reporte['accuracy']\n",
    "    \n",
    "    # Asegurar que la matriz de confusión tenga el tamaño adecuado\n",
    "    if matriz_confusion.shape != matriz_confusion_total.shape:\n",
    "        # Redimensionar matriz de confusión del fold actual\n",
    "        matriz_confusion_expanded = np.zeros_like(matriz_confusion_total)\n",
    "        matriz_confusion_expanded[:matriz_confusion.shape[0], :matriz_confusion.shape[1]] = matriz_confusion\n",
    "        matriz_confusion = matriz_confusion_expanded\n",
    "\n",
    "    # Acumular la matriz de confusión\n",
    "    matriz_confusion_total += matriz_confusion\n",
    "    \n",
    "# Calcular promedios de las métricas\n",
    "num_folds = len(folds)\n",
    "precision_promedio = precision_total / num_folds\n",
    "recall_promedio = recall_total / num_folds\n",
    "f1_score_promedio = f1_score_total / num_folds\n",
    "accuracy_promedio = accuracy_total / num_folds\n",
    "\n",
    "# Imprimir matriz de confusión total\n",
    "print(\"\\n**Fold con distancia minima**\")\n",
    "print(\"Matriz de Confusión Total:\")\n",
    "print(matriz_confusion_total)\n",
    "\n",
    "# Imprimir resultados generales promedio\n",
    "print(\"Resultados Promedio de Validación Cruzada:\")\n",
    "print(f\"Precisión Promedio: {precision_promedio:.2f}\")\n",
    "print(f\"Recall Promedio: {recall_promedio:.2f}\")\n",
    "print(f\"F1-Score Promedio: {f1_score_promedio:.2f}\")\n",
    "print(f\"Exactitud (Accuracy) Promedio: {accuracy_promedio:.2f}\")\n",
    "\n",
    "# Clasificador con 1NN\n",
    "clasificador = clasificador1NN()\n",
    "clasificador.ajustar(glassX_train,glassY_train)\n",
    "predicciones = clasificador.predecir(glassX_test)\n",
    "reporte_general, matriz_confusion = classificationReport(glassY_test, predicciones)\n",
    "print(\"\\n**Holdout con 1NN**\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(matriz_confusion)\n",
    "\n",
    "print(\"\\nReporte de Clasificación General:\")\n",
    "print(f\"Precisión: {reporte_general['precision_global']:.2f}\")\n",
    "print(f\"Recall: {reporte_general['recall_global']:.2f}\")\n",
    "print(f\"F1-Score: {reporte_general['f1_score_global']:.2f}\")\n",
    "print(f\"Exactitud (Accuracy): {reporte_general['accuracy']:.2f}\")\n",
    "\n",
    "\n",
    "precision_total = 0\n",
    "recall_total = 0\n",
    "f1_score_total = 0\n",
    "accuracy_total = 0\n",
    "\n",
    "num_clases = len(set(Yglass))  # Número de clases en el conjunto de datos\n",
    "matriz_confusion_total = np.zeros((num_clases, num_clases), dtype=int)\n",
    "\n",
    "for i, (X_train, X_test, y_train, y_test) in enumerate(folds):\n",
    "    clasificador.ajustar(X_train, y_train)\n",
    "    predictions = clasificador.predecir(X_test)\n",
    "\n",
    "    reporte, matriz_confusion = classificationReport(y_test, predictions)\n",
    "    \n",
    "    # Acumular las métricas de este fold\n",
    "    precision_total += reporte['precision_global']\n",
    "    recall_total += reporte['recall_global']\n",
    "    f1_score_total += reporte['f1_score_global']\n",
    "    accuracy_total += reporte['accuracy']\n",
    "    \n",
    "    # Asegurar que la matriz de confusión tenga el tamaño adecuado\n",
    "    if matriz_confusion.shape != matriz_confusion_total.shape:\n",
    "        # Redimensionar matriz de confusión del fold actual\n",
    "        matriz_confusion_expanded = np.zeros_like(matriz_confusion_total)\n",
    "        matriz_confusion_expanded[:matriz_confusion.shape[0], :matriz_confusion.shape[1]] = matriz_confusion\n",
    "        matriz_confusion = matriz_confusion_expanded\n",
    "\n",
    "    # Acumular la matriz de confusión\n",
    "    matriz_confusion_total += matriz_confusion\n",
    "\n",
    "# Calcular promedios de las métricas\n",
    "num_folds = len(folds)\n",
    "precision_promedio = precision_total / num_folds\n",
    "recall_promedio = recall_total / num_folds\n",
    "f1_score_promedio = f1_score_total / num_folds\n",
    "accuracy_promedio = accuracy_total / num_folds\n",
    "\n",
    "# Imprimir matriz de confusión total\n",
    "print(\"\\n**Fold con 1NN**\")\n",
    "print(\"Matriz de Confusión Total:\")\n",
    "print(matriz_confusion_total)\n",
    "\n",
    "# Imprimir resultados generales promedio\n",
    "print(\"Resultados Promedio de Validación Cruzada:\")\n",
    "print(f\"Precisión Promedio: {precision_promedio:.2f}\")\n",
    "print(f\"Recall Promedio: {recall_promedio:.2f}\")\n",
    "print(f\"F1-Score Promedio: {f1_score_promedio:.2f}\")\n",
    "print(f\"Exactitud (Accuracy) Promedio: {accuracy_promedio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb40c6e",
   "metadata": {},
   "source": [
    "## Segunda parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2505dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris_clean.csv')\n",
    "irisClass = iris[iris['class_encoded'].isin([0,2])]\n",
    "Xiris = irisClass.drop(columns=['class','class_encoded'])\n",
    "Yiris = irisClass['class_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "920ecc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Holdout con Perceptron**\n",
      "Matriz de Confusión:\n",
      "    0   2\n",
      "0  11   0\n",
      "2   0  19\n",
      "\n",
      "Reporte de Clasificación General:\n",
      "Precisión: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "Exactitud (Accuracy): 1.00\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(Learn_Rate=0.01, Iterations=100)\n",
    "X_train, X_test, y_train, y_test = hold_out_split(Xiris, Yiris)\n",
    "X_train = X_train.astype(float)\n",
    "y_train = y_train.astype(float)\n",
    "\n",
    "# Entrenar el modelo\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "predicciones = perceptron.predict(X_test)\n",
    "\n",
    "reporte_general, matriz_confusion = classificationReport(y_test, predicciones)\n",
    "print(\"\\n**Holdout con Perceptron**\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(matriz_confusion)\n",
    "\n",
    "print(\"\\nReporte de Clasificación General:\")\n",
    "print(f\"Precisión: {reporte_general['precision_global']:.2f}\")\n",
    "print(f\"Recall: {reporte_general['recall_global']:.2f}\")\n",
    "print(f\"F1-Score: {reporte_general['f1_score_global']:.2f}\")\n",
    "print(f\"Exactitud (Accuracy): {reporte_general['accuracy']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
